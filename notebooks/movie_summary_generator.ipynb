{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk0wAONSQSRH"
      },
      "source": [
        "# Movie Summary Generation with Gemini API\n",
        "\n",
        "## Overview\n",
        "This notebook generates AI-powered movie summaries for the MovieLens dataset using Google's Gemini 2.5 Flash via the new **google-genai** SDK with **parallel batch processing**.\n",
        "\n",
        "‚ö†Ô∏è **IMPORTANT:** If you're updating from an older version of this notebook, please **restart the runtime** before running:\n",
        "- Click: **Runtime ‚Üí Restart runtime**\n",
        "- Then run all cells from the beginning\n",
        "\n",
        "**Features:**\n",
        "- Test mode (25 movies) and Full mode (~9,700 movies)\n",
        "- **Parallel processing** with 50 concurrent workers\n",
        "- **Batch processing** for optimal throughput\n",
        "- Progress saving every 100 movies\n",
        "- Automatic retry logic for API failures\n",
        "- Clean CSV output ready for database import\n",
        "- Comprehensive error logging with inline error details\n",
        "\n",
        "**Performance:**\n",
        "- ~50x faster with parallel processing\n",
        "- Full dataset: **15-30 minutes** (vs 5-8 hours sequential)\n",
        "- ~300-600 movies per minute throughput\n",
        "- No grounding needed (movies are in training data)\n",
        "\n",
        "**Requirements:**\n",
        "- Colab Enterprise environment\n",
        "- Vertex AI API enabled in your GCP project\n",
        "- Proper IAM permissions (Vertex AI User role)\n",
        "\n",
        "**SDK:** Uses the new unified `google-genai` SDK (released late 2024)\n",
        "\n",
        "**Output Format:** `summaries.csv` with columns: `movieId,summary`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4qL7DrRQSRJ"
      },
      "source": [
        "## Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DmMt5YijQSRJ"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "# Using google-genai - the new unified SDK for Gemini API\n",
        "!pip install -q google-genai pandas tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M_jSD3JwQSRK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "from datetime import datetime\n",
        "from typing import Optional, Tuple\n",
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import threading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zXS_wOTfQzVI"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "_thread_local = threading.local()\n",
        "\n",
        "def get_client():\n",
        "    if getattr(_thread_local, \"client\", None) is None:\n",
        "        from google import genai\n",
        "        import google.auth\n",
        "        credentials, project_id = google.auth.default()\n",
        "        _thread_local.client = genai.Client(\n",
        "            vertexai=True,\n",
        "            project=project_id,\n",
        "            location='us-central1',\n",
        "        )\n",
        "    return _thread_local.client\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ykvddLRlQSRK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9fbac3a-212e-4225-8f77-5b0d4317649d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration:\n",
            "  Mode: FULL\n",
            "  Model: gemini-2.5-flash\n",
            "  Movies to process: ALL (~9,700)\n",
            "  Max workers: 50\n",
            "  Save interval: 100 movies\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "class Config:\n",
        "    \"\"\"Central configuration for the movie summary generator\"\"\"\n",
        "\n",
        "    # Mode: 'test' for 25 movies, 'full' for all movies\n",
        "    MODE = 'full'  # Change to 'full' for production run\n",
        "    DEBUG = True   # Set to True to see detailed error messages\n",
        "\n",
        "    # Data URLs and paths\n",
        "    INPUT_URL = 'https://raw.githubusercontent.com/haggman/cymbalflix/main/starter/data/ml-latest-small/movies.csv'\n",
        "    OUTPUT_FILE = 'summaries.csv'\n",
        "    PROGRESS_FILE = 'summary_progress.csv'\n",
        "    ERROR_LOG = 'summary_errors.csv'\n",
        "\n",
        "    # API Configuration\n",
        "    MODEL_NAME = 'gemini-2.5-flash'  # Latest fast model\n",
        "\n",
        "    # Processing settings\n",
        "    TEST_MODE_LIMIT = 25\n",
        "    SAVE_INTERVAL = 100  # Save progress every N movies\n",
        "    MAX_RETRIES = 3\n",
        "    RETRY_DELAY = 2  # seconds\n",
        "\n",
        "    # Batch processing for speed\n",
        "    BATCH_SIZE = 100  # Process this many movies concurrently\n",
        "    MAX_WORKERS = 50  # Number of parallel threads\n",
        "\n",
        "    # Summary requirements\n",
        "    MIN_SUMMARY_LENGTH = 50  # characters\n",
        "    MAX_SUMMARY_LENGTH = 3000  # characters\n",
        "\n",
        "# Display current configuration\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Mode: {Config.MODE.upper()}\")\n",
        "print(f\"  Model: {Config.MODEL_NAME}\")\n",
        "print(f\"  Movies to process: {Config.TEST_MODE_LIMIT if Config.MODE == 'test' else 'ALL (~9,700)'}\")\n",
        "print(f\"  Max workers: {Config.MAX_WORKERS}\")\n",
        "print(f\"  Save interval: {Config.SAVE_INTERVAL} movies\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRoUq05fQSRK"
      },
      "source": [
        "## Google GenAI SDK Setup\n",
        "\n",
        "**Note:** Using the new unified `google-genai` SDK. In Colab Enterprise, authentication is automatic via your project's default credentials.\n",
        "\n",
        "**Performance:** Grounding is disabled for speed since these movies (pre-2019) are already in Gemini's training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tW1ZAHx1QSRK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0065c1df-b8e7-4cfe-8bc1-046957484b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Authentication successful\n",
            "   Project: qwiklabs-gcp-01-5c40e6907a04\n",
            "   Location: us-central1\n",
            "   Using Vertex AI: True\n",
            "\n",
            "‚úÖ Ready to use model: gemini-2.5-flash\n"
          ]
        }
      ],
      "source": [
        "# Initialize Google GenAI client for Vertex AI\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "# Get project from environment\n",
        "try:\n",
        "    import google.auth\n",
        "\n",
        "    credentials, project_id = google.auth.default()\n",
        "\n",
        "    print(f\"‚úÖ Authentication successful\")\n",
        "    print(f\"   Project: {project_id}\")\n",
        "    print(f\"   Location: us-central1\")\n",
        "    print(f\"   Using Vertex AI: True\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Authentication error: {e}\")\n",
        "    print(\"Please ensure you're running in Colab Enterprise with proper permissions\")\n",
        "    raise\n",
        "\n",
        "print(f\"\\n‚úÖ Ready to use model: {Config.MODEL_NAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5gb-ZxxQSRL"
      },
      "source": [
        "## Summary Generation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sqraWS0UQSRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa60ffd3-ee97-490a-b1ab-382161c035d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Summary generation functions defined\n"
          ]
        }
      ],
      "source": [
        "def create_summary_prompt(title: str, year: Optional[int]) -> str:\n",
        "    # Convert pandas NA to None for boolean check\n",
        "    if pd.isna(year):\n",
        "        year = None\n",
        "\n",
        "    year_str = f\" ({year})\" if year else \"\"\n",
        "\n",
        "    \"\"\"Create a prompt for Gemini to generate a movie summary.\n",
        "\n",
        "    Args:\n",
        "        title: Clean movie title without year\n",
        "        year: Release year (if known)\n",
        "\n",
        "    Returns:\n",
        "        Formatted prompt string\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"Write a 1-2 paragraph summary of the movie \"{title}\"{year_str}.\n",
        "\n",
        "Include:\n",
        "- Brief plot overview (spoiler-free)\n",
        "- Notable cast and director\n",
        "- Critical reception and cultural impact\n",
        "\n",
        "Write 150-250 words in a neutral, encyclopedic tone.\"\"\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def generate_summary(title: str, year: Optional[int], retries: int = Config.MAX_RETRIES) -> Tuple[Optional[str], Optional[str]]:\n",
        "    \"\"\"Generate a movie summary using Gemini API with retry logic.\n",
        "\n",
        "    Args:\n",
        "        title: Clean movie title\n",
        "        year: Release year\n",
        "        retries: Number of retry attempts\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (summary, error_message). If successful, error_message is None.\n",
        "    \"\"\"\n",
        "    prompt = create_summary_prompt(title, year)\n",
        "\n",
        "    # Configure generation parameters (NO grounding for speed)\n",
        "    generate_config = types.GenerateContentConfig(\n",
        "        temperature=1.3,\n",
        "        tools=[types.Tool(google_search=types.GoogleSearch())],\n",
        "    )\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = get_client().models.generate_content(\n",
        "                model=Config.MODEL_NAME,\n",
        "                contents=prompt,\n",
        "                config=generate_config,\n",
        "            )\n",
        "\n",
        "            if Config.DEBUG and Config.MODE == 'test' and attempt == 0:\n",
        "                print(f\"\\n  DEBUG - Movie: {title} ({year})\")\n",
        "                print(f\"  Response type: {type(response)}\")\n",
        "                print(f\"  Has text attr: {hasattr(response, 'text')}\")\n",
        "                if hasattr(response, 'candidates'):\n",
        "                    print(f\"  Candidates: {len(response.candidates) if response.candidates else 0}\")\n",
        "\n",
        "            # Extract text from response\n",
        "            summary = None\n",
        "\n",
        "            if hasattr(response, 'text') and response.text:\n",
        "                summary = response.text\n",
        "                if Config.DEBUG and Config.MODE == 'test' and attempt == 0:\n",
        "                    print(f\"  Got text via response.text: {len(summary)} chars\")\n",
        "            elif hasattr(response, 'candidates') and response.candidates:\n",
        "                candidate = response.candidates[0]\n",
        "                if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):\n",
        "                    parts = candidate.content.parts\n",
        "                    if parts and hasattr(parts[0], 'text'):\n",
        "                        summary = parts[0].text\n",
        "                        if Config.DEBUG and Config.MODE == 'test' and attempt == 0:\n",
        "                            print(f\"  Got text via candidates: {len(summary)} chars\")\n",
        "\n",
        "            # Check if we got valid text\n",
        "            if not summary:\n",
        "                if Config.DEBUG and Config.MODE == 'test':\n",
        "                    print(f\"  No summary extracted on attempt {attempt + 1}\")\n",
        "                if attempt < retries - 1:\n",
        "                    time.sleep(Config.RETRY_DELAY)\n",
        "                    continue\n",
        "                return None, \"No summary text in API response\"\n",
        "\n",
        "            summary = summary.strip()\n",
        "\n",
        "            # Validate summary quality\n",
        "            if not summary or len(summary) < Config.MIN_SUMMARY_LENGTH:\n",
        "                if attempt < retries - 1:\n",
        "                    time.sleep(Config.RETRY_DELAY)\n",
        "                    continue\n",
        "                return None, f\"Summary too short ({len(summary)} chars)\"\n",
        "\n",
        "            if len(summary) > Config.MAX_SUMMARY_LENGTH:\n",
        "                summary = summary[:Config.MAX_SUMMARY_LENGTH] + \"...\"\n",
        "\n",
        "            return summary, None\n",
        "\n",
        "        except AttributeError as e:\n",
        "            error_msg = f\"AttributeError: {str(e)}\"\n",
        "            if Config.DEBUG and Config.MODE == 'test':\n",
        "                print(f\"  {error_msg} on attempt {attempt + 1}\")\n",
        "            if attempt < retries - 1:\n",
        "                time.sleep(Config.RETRY_DELAY * (attempt + 1))\n",
        "                continue\n",
        "            return None, error_msg\n",
        "        except Exception as e:\n",
        "            error_msg = f\"{type(e).__name__}: {str(e)}\"\n",
        "            if Config.DEBUG and Config.MODE == 'test':\n",
        "                print(f\"  {error_msg} on attempt {attempt + 1}\")\n",
        "            if attempt < retries - 1:\n",
        "                time.sleep(Config.RETRY_DELAY * (attempt + 1))\n",
        "                continue\n",
        "            return None, error_msg\n",
        "\n",
        "    return None, \"Max retries exceeded\"\n",
        "\n",
        "\n",
        "def clean_summary_for_csv(summary: str) -> str:\n",
        "    \"\"\"Clean summary text for CSV output following MovieLens format.\n",
        "\n",
        "    Args:\n",
        "        summary: Raw summary text\n",
        "\n",
        "    Returns:\n",
        "        Cleaned summary suitable for CSV (double-quote escaped, UTF-8)\n",
        "    \"\"\"\n",
        "    if not summary:\n",
        "        return \"\"\n",
        "\n",
        "    # Remove excessive whitespace\n",
        "    summary = re.sub(r'\\s+', ' ', summary)\n",
        "\n",
        "    # CSV standard: escape double quotes by doubling them\n",
        "    summary = summary.replace('\"', '\"\"')\n",
        "\n",
        "    return summary.strip()\n",
        "\n",
        "print(\"‚úÖ Summary generation functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDoI13K6QSRK"
      },
      "source": [
        "## Test API Connection\n",
        "\n",
        "Quick test to verify the API is working correctly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VGZo7PwbQSRK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9c43fd-0048-46ec-c31c-99681be8c512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API Test Successful!\n",
            "Response type: <class 'google.genai.types.GenerateContentResponse'>\n",
            "Has text attribute: True\n",
            "Text is None: False\n",
            "Sample text: When a new, high-tech action figure named Buzz Lightyear threatens his status, a pull-string cowboy \n",
            "\n",
            "============================================================\n",
            "Testing summary generation...\n",
            "============================================================\n",
            "\n",
            "‚úÖ Summary generation working!\n",
            "Length: 1589 characters\n",
            "Preview: \"Toy Story\" (1995), directed by John Lasseter, is a pioneering animated film that introduced audiences to a world where toys come to life when humans are absent. The plot centers on Woody (voiced by T...\n"
          ]
        }
      ],
      "source": [
        "# Test with a simple movie to verify API response format\n",
        "try:\n",
        "    test_config = types.GenerateContentConfig(\n",
        "        temperature=0.7,\n",
        "        max_output_tokens=200,\n",
        "    )\n",
        "\n",
        "    test_response = get_client().models.generate_content(\n",
        "        model=Config.MODEL_NAME,\n",
        "        contents='Write one sentence about the movie Toy Story.',\n",
        "        config=test_config,\n",
        "    )\n",
        "\n",
        "    print(\"‚úÖ API Test Successful!\")\n",
        "    print(f\"Response type: {type(test_response)}\")\n",
        "    print(f\"Has text attribute: {hasattr(test_response, 'text')}\")\n",
        "\n",
        "    if hasattr(test_response, 'text'):\n",
        "        print(f\"Text is None: {test_response.text is None}\")\n",
        "        if test_response.text:\n",
        "            print(f\"Sample text: {test_response.text[:100]}\")\n",
        "    else:\n",
        "        print(f\"Response object: {test_response}\")\n",
        "        print(f\"Response dir: {[attr for attr in dir(test_response) if not attr.startswith('_')]}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå API Test Failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "# Test generating a movie summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Testing summary generation...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "test_summary, test_error = generate_summary(\"Toy Story\", 1995)\n",
        "if test_summary:\n",
        "    print(f\"\\n‚úÖ Summary generation working!\")\n",
        "    print(f\"Length: {len(test_summary)} characters\")\n",
        "    print(f\"Preview: {test_summary[:200]}...\")\n",
        "else:\n",
        "    print(f\"\\n‚ùå Summary generation failed: {test_error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJLqOFjDQSRL"
      },
      "source": [
        "## Load and Prepare Movie Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KQY49p9DQSRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e09fae4-b257-47d7-9e57-adbb4976e09e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading movie data from: https://raw.githubusercontent.com/haggman/cymbalflix/main/starter/data/ml-latest-small/movies.csv\n",
            "\n",
            "‚úÖ FULL MODE: Processing all 9742 movies\n",
            "\n",
            "Dataset info:\n",
            "  Total movies: 9742\n",
            "  Movies with years: 9729\n",
            "  Year range: 1902 - 2018\n",
            "\n",
            "Sample movies:\n",
            "   movieId                               title                  clean_title  \\\n",
            "0        1                    Toy Story (1995)                    Toy Story   \n",
            "1        2                      Jumanji (1995)                      Jumanji   \n",
            "2        3             Grumpier Old Men (1995)             Grumpier Old Men   \n",
            "3        4            Waiting to Exhale (1995)            Waiting to Exhale   \n",
            "4        5  Father of the Bride Part II (1995)  Father of the Bride Part II   \n",
            "\n",
            "   year                                       genres  \n",
            "0  1995  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "1  1995                   Adventure|Children|Fantasy  \n",
            "2  1995                               Comedy|Romance  \n",
            "3  1995                         Comedy|Drama|Romance  \n",
            "4  1995                                       Comedy  \n"
          ]
        }
      ],
      "source": [
        "def extract_year_from_title(title: str) -> Tuple[str, Optional[int]]:\n",
        "    \"\"\"Extract year from movie title.\n",
        "\n",
        "    Args:\n",
        "        title: Movie title potentially containing year in format \"Title (YYYY)\"\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (clean_title, year)\n",
        "    \"\"\"\n",
        "    # Match year in parentheses at end of title\n",
        "    match = re.search(r'\\((\\d{4})\\)\\s*$', title)\n",
        "\n",
        "    if match:\n",
        "        year = int(match.group(1))\n",
        "        clean_title = title[:match.start()].strip()\n",
        "        return clean_title, year\n",
        "\n",
        "    return title.strip(), None\n",
        "\n",
        "\n",
        "# Load movie data\n",
        "print(f\"Loading movie data from: {Config.INPUT_URL}\")\n",
        "df = pd.read_csv(Config.INPUT_URL)\n",
        "\n",
        "# Apply mode limit\n",
        "if Config.MODE == 'test':\n",
        "    df = df.head(Config.TEST_MODE_LIMIT)\n",
        "    print(f\"\\n‚ö†Ô∏è  TEST MODE: Processing first {Config.TEST_MODE_LIMIT} movies only\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ FULL MODE: Processing all {len(df)} movies\")\n",
        "\n",
        "# Extract years from titles\n",
        "df[['clean_title', 'year']] = df['title'].apply(\n",
        "    lambda x: pd.Series(extract_year_from_title(x))\n",
        ")\n",
        "\n",
        "# Convert year to nullable integer type (keeps integers, allows None)\n",
        "df['year'] = df['year'].astype('Int64')  # Capital I - nullable integer dtype\n",
        "\n",
        "\n",
        "# Validate years (should be reasonable movie years)\n",
        "valid_years = df['year'].notna() & (df['year'] >= 1888) & (df['year'] <= 2030)\n",
        "invalid_year_count = (~valid_years & df['year'].notna()).sum()\n",
        "if invalid_year_count > 0:\n",
        "    print(f\"\\n‚ö†Ô∏è  Warning: Found {invalid_year_count} movies with invalid years, setting to None\")\n",
        "    df.loc[~valid_years, 'year'] = None\n",
        "\n",
        "print(f\"\\nDataset info:\")\n",
        "print(f\"  Total movies: {len(df)}\")\n",
        "print(f\"  Movies with years: {df['year'].notna().sum()}\")\n",
        "if df['year'].notna().sum() > 0:\n",
        "    print(f\"  Year range: {df['year'].min():.0f} - {df['year'].max():.0f}\")\n",
        "\n",
        "# Display sample\n",
        "print(f\"\\nSample movies:\")\n",
        "print(df[['movieId', 'title', 'clean_title', 'year', 'genres']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mV9xWSWQSRL"
      },
      "source": [
        "## Progress Tracking Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6plqPhu3QSRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2510134-26a2-4a7a-e410-53bf3f728f82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Progress tracking functions defined\n"
          ]
        }
      ],
      "source": [
        "def save_progress(df_processed: pd.DataFrame, filename: str = Config.PROGRESS_FILE):\n",
        "    \"\"\"Save processed summaries to CSV.\n",
        "\n",
        "    Args:\n",
        "        df_processed: DataFrame with movieId and summary columns\n",
        "        filename: Output filename\n",
        "    \"\"\"\n",
        "    # Select only the required columns: movieId and summary\n",
        "    output_cols = ['movieId', 'summary']\n",
        "    df_output = df_processed[output_cols].copy()\n",
        "\n",
        "    # Save to CSV with UTF-8 encoding and proper quoting for MovieLens format\n",
        "    df_output.to_csv(filename, index=False, encoding='utf-8', quoting=csv.QUOTE_MINIMAL)\n",
        "    print(f\"  üíæ Progress saved: {filename} ({len(df_output)} movies)\")\n",
        "\n",
        "\n",
        "def log_error(movie_id: int, title: str, error_msg: str, filename: str = Config.ERROR_LOG):\n",
        "    \"\"\"Log errors to CSV file.\n",
        "\n",
        "    Args:\n",
        "        movie_id: Movie ID\n",
        "        title: Movie title\n",
        "        error_msg: Error message\n",
        "        filename: Error log filename\n",
        "    \"\"\"\n",
        "    error_data = {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'movieId': movie_id,\n",
        "        'title': title,\n",
        "        'error': error_msg\n",
        "    }\n",
        "\n",
        "    file_exists = Path(filename).exists()\n",
        "\n",
        "    with open(filename, 'a', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=['timestamp', 'movieId', 'title', 'error'])\n",
        "        if not file_exists:\n",
        "            writer.writeheader()\n",
        "        writer.writerow(error_data)\n",
        "\n",
        "print(\"‚úÖ Progress tracking functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9RuBIoNQSRL"
      },
      "source": [
        "## Parallel Batch Processing\n",
        "\n",
        "**Speed optimization:** Processes movies in batches with multiple concurrent workers for ~50x faster throughput."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_76YRm5dQSRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a532788-7697-4c5f-d430-550eb43eb52c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Parallel processing functions defined\n"
          ]
        }
      ],
      "source": [
        "def process_single_movie(row: pd.Series) -> dict:\n",
        "    \"\"\"Process a single movie (called by worker threads).\n",
        "\n",
        "    Args:\n",
        "        row: DataFrame row with movie data\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with movie result\n",
        "    \"\"\"\n",
        "    movie_id = row['movieId']\n",
        "    title = row['title']\n",
        "    clean_title = row['clean_title']\n",
        "    year = row['year']\n",
        "\n",
        "    # Print individual movie progress only in test mode\n",
        "    if Config.MODE == 'test':\n",
        "        print(f\"  Processing: {title}\")\n",
        "\n",
        "    # Generate summary\n",
        "    summary, error = generate_summary(clean_title, year)\n",
        "\n",
        "    if summary:\n",
        "        summary_clean = clean_summary_for_csv(summary)\n",
        "        return {\n",
        "            'movieId': movie_id,\n",
        "            'summary': summary_clean,\n",
        "            'error': None\n",
        "        }\n",
        "    else:\n",
        "        # Log error to separate file\n",
        "        log_error(movie_id, title, error)\n",
        "\n",
        "        # Include error details inline in the summary field\n",
        "        error_summary = f\"[Summary generation failed: {error}]\"\n",
        "        return {\n",
        "            'movieId': movie_id,\n",
        "            'summary': error_summary,\n",
        "            'error': error\n",
        "        }\n",
        "\n",
        "\n",
        "def process_movies(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Process all movies with parallel batch processing for speed.\n",
        "\n",
        "    Automatically resumes from progress file if it exists, skipping already-processed movies.\n",
        "\n",
        "    Args:\n",
        "        df: Input DataFrame with movies\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with summaries added\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    errors = []\n",
        "\n",
        "    # Check for existing progress and load it\n",
        "    progress_path = Path(Config.PROGRESS_FILE)\n",
        "    processed_ids = set()\n",
        "\n",
        "    if progress_path.exists():\n",
        "        print(f\"\\nüìÇ Found existing progress file: {Config.PROGRESS_FILE}\")\n",
        "        df_progress = pd.read_csv(Config.PROGRESS_FILE)\n",
        "\n",
        "        # Only skip movies that have successful summaries OR non-error summaries\n",
        "        # Re-process any that have error messages\n",
        "        successful_progress = df_progress[~df_progress['summary'].str.contains(r'\\[Summary generation failed', na=False)]\n",
        "        processed_ids = set(successful_progress['movieId'])\n",
        "\n",
        "        # Keep successful summaries in results\n",
        "        for _, row in successful_progress.iterrows():\n",
        "            results.append({\n",
        "                'movieId': row['movieId'],\n",
        "                'summary': row['summary'],\n",
        "                'error': None\n",
        "            })\n",
        "\n",
        "        # Check for failed summaries to retry\n",
        "        failed_ids = set(df_progress[df_progress['summary'].str.contains(r'\\[Summary generation failed', na=False)]['movieId'])\n",
        "\n",
        "        print(f\"  ‚úÖ Loaded {len(successful_progress)} successful summaries\")\n",
        "        print(f\"  üîÑ Will retry {len(failed_ids)} failed summaries\")\n",
        "        print(f\"  üìù Remaining to process: {len(df) - len(processed_ids)}\")\n",
        "\n",
        "    # Filter to only unprocessed movies\n",
        "    df_to_process = df[~df['movieId'].isin(processed_ids)].copy()\n",
        "\n",
        "    if len(df_to_process) == 0:\n",
        "        print(f\"\\n‚úÖ All movies already processed! Loading final results...\")\n",
        "        df_final = pd.read_csv(Config.PROGRESS_FILE)\n",
        "        return df_final\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Starting PARALLEL summary generation\")\n",
        "    print(f\"  Total movies in dataset: {len(df)}\")\n",
        "    print(f\"  Already processed: {len(processed_ids)}\")\n",
        "    print(f\"  Movies to process: {len(df_to_process)}\")\n",
        "    print(f\"  Batch size: {Config.BATCH_SIZE}\")\n",
        "    print(f\"  Workers: {Config.MAX_WORKERS}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Process in batches with parallel workers\n",
        "    total_batches = (len(df_to_process) + Config.BATCH_SIZE - 1) // Config.BATCH_SIZE\n",
        "\n",
        "    with tqdm(total=len(df_to_process), desc=\"Generating summaries\", disable=(Config.MODE == 'test')) as pbar:\n",
        "        for batch_num in range(total_batches):\n",
        "            start_idx = batch_num * Config.BATCH_SIZE\n",
        "            end_idx = min(start_idx + Config.BATCH_SIZE, len(df_to_process))\n",
        "            batch_df = df_to_process.iloc[start_idx:end_idx]\n",
        "\n",
        "            # Process batch in parallel\n",
        "            with ThreadPoolExecutor(max_workers=Config.MAX_WORKERS) as executor:\n",
        "                # Submit all movies in batch\n",
        "                futures = {\n",
        "                    executor.submit(process_single_movie, row): idx\n",
        "                    for idx, row in batch_df.iterrows()\n",
        "                }\n",
        "\n",
        "                # Collect results as they complete\n",
        "                for future in as_completed(futures):\n",
        "                    result = future.result()\n",
        "                    results.append(result)\n",
        "\n",
        "                    if result['error']:\n",
        "                        errors.append(result['movieId'])\n",
        "\n",
        "                    if Config.MODE != 'test':\n",
        "                        pbar.update(1)\n",
        "\n",
        "            # Save progress after each batch\n",
        "            if len(results) % Config.SAVE_INTERVAL == 0 or end_idx == len(df_to_process):\n",
        "                df_progress = pd.DataFrame(results)\n",
        "                # Remove error column before saving\n",
        "                df_progress = df_progress.drop(columns=['error'])\n",
        "                save_progress(df_progress, Config.PROGRESS_FILE)\n",
        "\n",
        "    # Final save\n",
        "    df_results = pd.DataFrame(results)\n",
        "    df_results = df_results.drop(columns=['error'])\n",
        "    save_progress(df_results, Config.OUTPUT_FILE)\n",
        "\n",
        "    # Summary statistics\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Processing Complete!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"  Total movies in dataset: {len(df)}\")\n",
        "    print(f\"  Newly processed: {len(df_to_process)}\")\n",
        "    print(f\"  Total with summaries: {len(df_results)}\")\n",
        "    print(f\"  Successful: {len(df_results) - len(errors)}\")\n",
        "    print(f\"  Errors: {len(errors)}\")\n",
        "    if len(df_to_process) > 0:\n",
        "        print(f\"  Time elapsed: {elapsed/60:.1f} minutes ({elapsed/3600:.1f} hours)\")\n",
        "        print(f\"  Average time per movie: {elapsed/len(df_to_process):.2f} seconds\")\n",
        "        print(f\"  Effective throughput: {len(df_to_process)/elapsed*60:.1f} movies/minute\")\n",
        "    print(f\"\\n  Output file: {Config.OUTPUT_FILE}\")\n",
        "\n",
        "    if errors:\n",
        "        print(f\"  Error log: {Config.ERROR_LOG}\")\n",
        "        print(f\"  Error rate: {len(errors)/len(df_results)*100:.1f}%\")\n",
        "\n",
        "    return df_results\n",
        "\n",
        "print(\"‚úÖ Parallel processing functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syy5fMaIQSRM"
      },
      "source": [
        "## Run Summary Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "3ZMTsV4KQSRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72bf5536-9cf8-46d8-c440-ca0014f539d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÇ Found existing progress file: summary_progress.csv\n",
            "  ‚úÖ Loaded 9742 successful summaries\n",
            "  üîÑ Will retry 0 failed summaries\n",
            "  üìù Remaining to process: 0\n",
            "\n",
            "‚úÖ All movies already processed! Loading final results...\n"
          ]
        }
      ],
      "source": [
        "# Run the processing\n",
        "df_with_summaries = process_movies(df)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37cab1b4",
        "outputId": "c8d0cd68-97b9-4195-d1c2-917060107007"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the summary_progress.csv file\n",
        "try:\n",
        "    df_progress = pd.read_csv('/content/summary_progress.csv')\n",
        "\n",
        "    # Filter for failed summaries\n",
        "    # Correcting the regex to properly escape the '[' character to avoid SyntaxWarning\n",
        "    failed_summaries = df_progress[df_progress['summary'].str.contains(r'\\[Summary generation failed', na=False)]\n",
        "\n",
        "    if not failed_summaries.empty:\n",
        "        print(f\"Found {len(failed_summaries)} failed summary messages:\")\n",
        "        display(failed_summaries)\n",
        "    else:\n",
        "        print(\"No failed summary messages found in 'summary_progress.csv'.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'summary_progress.csv' not found. Please ensure the file exists.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No failed summary messages found in 'summary_progress.csv'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:8: SyntaxWarning: invalid escape sequence '\\['\n",
            "<>:8: SyntaxWarning: invalid escape sequence '\\['\n",
            "/tmp/ipython-input-1408209446.py:8: SyntaxWarning: invalid escape sequence '\\['\n",
            "  failed_summaries = df_progress[df_progress['summary'].str.contains('\\[Summary generation failed', na=False)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUDtnVW1QSRM"
      },
      "source": [
        "## Verify Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "u66uvpreQSRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76a1b7a5-5cc4-4169-f74f-852fc07042ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Sample Results:\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Movie #1:\n",
            "  ID: 24\n",
            "  Summary: The 1995 science fiction drama \"\"Powder,\"\" directed and written by Victor Salva, tells the story of Jeremy \"\"Powder\"\" Reed, an albino teenager with extraordinary intellect and unique telepathic and ps...\n",
            "  Summary length: 1587 characters\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Movie #2:\n",
            "  ID: 6\n",
            "  Summary: Michael Mann's 1995 crime drama, \"\"Heat,\"\" meticulously chronicles the high-stakes cat-and-mouse game between a seasoned crew of professional thieves and a determined unit of LAPD robbery-homicide det...\n",
            "  Summary length: 1370 characters\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Movie #3:\n",
            "  ID: 1\n",
            "  Summary: \"\"Toy Story,\"\" released in 1995, is an American animated adventure comedy film produced by Pixar Animation Studios and distributed by Walt Disney Pictures. It tells the story of a group of toys who co...\n",
            "  Summary length: 1713 characters\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Display sample results\n",
        "print(\"\\nüìä Sample Results:\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for idx in range(min(3, len(df_with_summaries))):\n",
        "    row = df_with_summaries.iloc[idx]\n",
        "    print(f\"\\nMovie #{idx+1}:\")\n",
        "    print(f\"  ID: {row['movieId']}\")\n",
        "    print(f\"  Summary: {row['summary'][:200]}...\")\n",
        "    print(f\"  Summary length: {len(row['summary'])} characters\")\n",
        "    print(\"-\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "oKAX1cS-QSRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "568f6dee-2333-4f3e-e23e-9fb967474533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Quality Checks:\n",
            "\n",
            "  Missing summaries: 0\n",
            "  Failed summaries: 0\n",
            "\n",
            "  Summary length statistics:\n",
            "    Min: 673 characters\n",
            "    Max: 3014 characters\n",
            "    Mean: 1484 characters\n",
            "    Median: 1477 characters\n",
            "\n",
            "  Summaries in target range (150-250 chars): 9332 (95.8%)\n",
            "\n",
            "  Completeness check:\n",
            "    Original movies: 9742\n",
            "    Movies with summaries: 9742\n",
            "    Missing summaries: 0\n",
            "    Extra summaries: 0\n",
            "    ‚úÖ Perfect match! All movies have summaries.\n"
          ]
        }
      ],
      "source": [
        "# Quality checks\n",
        "print(\"\\nüîç Quality Checks:\\n\")\n",
        "\n",
        "# Check for missing summaries\n",
        "missing = df_with_summaries['summary'].isna().sum()\n",
        "failed = df_with_summaries['summary'].str.contains(r'\\[Summary generation failed', na=False).sum()\n",
        "print(f\"  Missing summaries: {missing}\")\n",
        "print(f\"  Failed summaries: {failed}\")\n",
        "\n",
        "# Summary length distribution\n",
        "df_with_summaries['summary_length'] = df_with_summaries['summary'].str.len()\n",
        "print(f\"\\n  Summary length statistics:\")\n",
        "print(f\"    Min: {df_with_summaries['summary_length'].min()} characters\")\n",
        "print(f\"    Max: {df_with_summaries['summary_length'].max()} characters\")\n",
        "print(f\"    Mean: {df_with_summaries['summary_length'].mean():.0f} characters\")\n",
        "print(f\"    Median: {df_with_summaries['summary_length'].median():.0f} characters\")\n",
        "\n",
        "# Check for summaries within target range (excluding failures)\n",
        "successful_summaries = df_with_summaries[~df_with_summaries['summary'].str.contains(r'\\[Summary generation failed', na=False)]\n",
        "in_range = successful_summaries[\n",
        "    (successful_summaries['summary_length'] >= 900) &\n",
        "    (successful_summaries['summary_length'] <= 1800)\n",
        "]\n",
        "if len(successful_summaries) > 0:\n",
        "    print(f\"\\n  Summaries in target range (150-250 chars): {len(in_range)} ({len(in_range)/len(successful_summaries)*100:.1f}%)\")\n",
        "\n",
        "# Check for completeness - every movie should have a summary\n",
        "print(f\"\\n  Completeness check:\")\n",
        "original_movie_ids = set(df['movieId'])\n",
        "summary_movie_ids = set(df_with_summaries['movieId'])\n",
        "\n",
        "missing_summaries = original_movie_ids - summary_movie_ids\n",
        "extra_summaries = summary_movie_ids - original_movie_ids\n",
        "\n",
        "print(f\"    Original movies: {len(original_movie_ids)}\")\n",
        "print(f\"    Movies with summaries: {len(summary_movie_ids)}\")\n",
        "print(f\"    Missing summaries: {len(missing_summaries)}\")\n",
        "print(f\"    Extra summaries: {len(extra_summaries)}\")\n",
        "\n",
        "if len(missing_summaries) == 0 and len(extra_summaries) == 0:\n",
        "    print(f\"    ‚úÖ Perfect match! All movies have summaries.\")\n",
        "elif len(missing_summaries) > 0:\n",
        "    print(f\"    ‚ö†Ô∏è  Missing summaries for movie IDs: {sorted(list(missing_summaries))[:10]}{'...' if len(missing_summaries) > 10 else ''}\")\n",
        "if len(extra_summaries) > 0:\n",
        "    print(f\"    ‚ö†Ô∏è  Extra summaries for movie IDs: {sorted(list(extra_summaries))[:10]}{'...' if len(extra_summaries) > 10 else ''}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg45KbwtQSRM"
      },
      "source": [
        "## Download Results\n",
        "\n",
        "Your results are saved to `summaries.csv`. You can download it from the files panel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "e2b-FadrQSRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4772d0-5d35-42ba-ae06-7f9f621abd72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Output file ready for download:\n",
            "  Filename: summaries.csv\n",
            "  Size: 14309.9 KB\n",
            "  Records: 9742\n",
            "  Format: movieId,summary\n",
            "\n",
            "  Download from the files panel on the left ‚Üí\n"
          ]
        }
      ],
      "source": [
        "# Display final file info\n",
        "from pathlib import Path\n",
        "\n",
        "output_path = Path(Config.OUTPUT_FILE)\n",
        "if output_path.exists():\n",
        "    file_size = output_path.stat().st_size / 1024  # KB\n",
        "    print(f\"\\n‚úÖ Output file ready for download:\")\n",
        "    print(f\"  Filename: {Config.OUTPUT_FILE}\")\n",
        "    print(f\"  Size: {file_size:.1f} KB\")\n",
        "    print(f\"  Records: {len(df_with_summaries)}\")\n",
        "    print(f\"  Format: movieId,summary\")\n",
        "    print(f\"\\n  Download from the files panel on the left ‚Üí\")\n",
        "else:\n",
        "    print(f\"‚ùå Output file not found: {Config.OUTPUT_FILE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV8RRrRLQSRM"
      },
      "source": [
        "## Resume Processing\n",
        "\n",
        "**Good news!** The notebook now automatically resumes from where it left off.\n",
        "\n",
        "- If processing is interrupted, simply re-run the \"Run Summary Generation\" cell\n",
        "- Already-processed successful summaries will be loaded automatically\n",
        "- Only failed summaries and unprocessed movies will be regenerated\n",
        "- Progress is saved every 100 movies to minimize data loss\n",
        "\n",
        "The resume logic:\n",
        "- ‚úÖ Skips movies with successful summaries\n",
        "- üîÑ Retries movies that previously failed\n",
        "- üìù Processes any remaining movies\n",
        "\n",
        "To start completely fresh, delete these files:\n",
        "- `summary_progress.csv`\n",
        "- `summaries.csv`\n",
        "- `summary_errors.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bf7g4PASQSRM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmzo5y0XQSRM"
      },
      "source": [
        "## Troubleshooting\n",
        "\n",
        "### Common Issues\n",
        "\n",
        "**403 Authentication Error:**\n",
        "- Ensure Vertex AI API is enabled in your GCP project\n",
        "- Verify you have the 'Vertex AI User' IAM role\n",
        "- Check that you're running in Colab Enterprise (not regular Colab)\n",
        "\n",
        "**Rate Limiting:**\n",
        "- Reduce `Config.MAX_WORKERS` (try 25 or 10)\n",
        "- Increase `Config.RETRY_DELAY` to slow down retries\n",
        "\n",
        "**API Quota Exceeded:**\n",
        "- Check your Vertex AI quotas in GCP Console\n",
        "- Reduce `Config.MAX_WORKERS` to lower concurrent requests\n",
        "- Run in test mode first to verify everything works\n",
        "\n",
        "**To Enable Vertex AI:**\n",
        "```bash\n",
        "gcloud services enable aiplatform.googleapis.com\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "movie_summary_generator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}